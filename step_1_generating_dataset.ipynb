{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import gzip\n",
    "import shutil\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TIME = time.time()\n",
    "\n",
    "BASE_URL = \"https://datasets.imdbws.com/\"\n",
    "\n",
    "FILES_IMDB = {\n",
    "    \"tit_bas\": \"title.basics.tsv\",\n",
    "    \"tit_rate\": \"title.ratings.tsv\",\n",
    "    \"name_bas\": \"name.basics.tsv\",\n",
    "    \"cast_crew\": \"title.principals.tsv\",\n",
    "}\n",
    "\n",
    "FILES_HAND = {\n",
    "    \"add_seen\": \"add_movies_seen.txt\",\n",
    "    \"add_unseen\": \"add_movies_unseen.txt\",\n",
    "    \"add_secop\": \"add_movies_second_opinion.txt\",\n",
    "    \"raw_status\": \"raw_status.xlsx\"\n",
    "}\n",
    "\n",
    "FILES_GENERATED = {\n",
    "    \"films_raw\": \"films_raw.pkl\"\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to True is you want to update the imdb files\n",
    "DOWNLOAD = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes old files if already excist\n",
    "if DOWNLOAD:\n",
    "\n",
    "    if not os.path.exists(\"data/imdb\"):\n",
    "        os.makedirs(\"data/imdb\")\n",
    "    \n",
    "    for file in FILES_IMDB.values():\n",
    "        file_name = os.path.join(\"data/imdb/\",file)\n",
    "        file_zip = file_name+\".gz\"\n",
    "        file_url = BASE_URL+file+\".gz\"\n",
    "        \n",
    "        # remove old files\n",
    "        if os.path.exists(file_name):\n",
    "            os.remove(file_name)\n",
    "        if os.path.exists(file_zip):\n",
    "            os.remove(file_zip)\n",
    "        \n",
    "        # download files\n",
    "        response = requests.get(file_url)\n",
    "        open(file_zip , \"wb\").write(response.content)\n",
    "\n",
    "        # unzip files\n",
    "        with gzip.open(file_zip, 'rb') as f_in:\n",
    "            with open(file_name, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        \n",
    "        # remove zips\n",
    "        os.remove(file_zip)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Generating a raw dataset for mining"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding new movies to raw_watched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the new seen movies\n",
    "seen_path = os.path.join(\"data\", \"handcrafted\", FILES_HAND[\"add_seen\"])\n",
    "seen_raw_f = open(seen_path,'r')\n",
    "seen_raw = seen_raw_f.readlines()\n",
    "\n",
    "# transforming the new seen movie data\n",
    "for linei in range(len(seen_raw)):\n",
    "    seen_raw[linei] = seen_raw[linei].strip().split(\"|\")\n",
    "    # getting the imdb code\n",
    "    url = seen_raw[linei][0].split(\"/\")\n",
    "    # temp = seen etc..\n",
    "    tofind = re.compile(\"^tt\\d+\\d$\")\n",
    "    ttcode = \"\"\n",
    "    for x in url:\n",
    "        y = tofind.findall(x)\n",
    "        if len(list(y)) != 0:\n",
    "            ttcode = list(y)[0]\n",
    "    \n",
    "    if len(seen_raw[linei]) == 1:\n",
    "        # only url\n",
    "        seen_raw[linei] = [ttcode, None, None]\n",
    "    elif len(seen_raw[linei]) == 2:\n",
    "        # url and score\n",
    "        seen_raw[linei] = [ttcode, float(seen_raw[linei][1]), None]\n",
    "    elif len(seen_raw[linei]) == 3:\n",
    "        # url and date, possibly also a score\n",
    "        row2 = seen_raw[linei][1]\n",
    "        row3 = seen_raw[linei][2]\n",
    "        if row2 == '':\n",
    "            row2 = None\n",
    "        else:\n",
    "            row2 = float(row2)\n",
    "        filmdate = row3.split(\"-\")\n",
    "        filmdate = date(int(filmdate[2]), int(filmdate[1]), int(filmdate[0]))\n",
    "        \n",
    "        seen_raw[linei] = [ttcode, row2, filmdate]\n",
    "seen_raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the new unseen movies\n",
    "unseen_path = os.path.join(\"data\", \"handcrafted\", FILES_HAND[\"add_unseen\"])\n",
    "unseen_raw_f = open(unseen_path,'r')\n",
    "unseen_raw = unseen_raw_f.readlines()\n",
    "\n",
    "# transforming the new unseen movie data\n",
    "for linei in range(len(unseen_raw)):\n",
    "    unseen_raw[linei] = unseen_raw[linei].strip()\n",
    "    temp = unseen_raw[linei].split(\"/\")\n",
    "    \n",
    "    tofind = re.compile(\"^tt\\d+\\d$\")\n",
    "    ttcode = \"\"\n",
    "    for x in temp:\n",
    "        y = tofind.findall(x)\n",
    "        if len(list(y)) != 0:\n",
    "            ttcode = list(y)[0]\n",
    "    unseen_raw[linei] = ttcode\n",
    "unseen_raw"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the 2d list to the raw_watched.xlsx (if not already added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_and_status = os.path.join(\"data\", \"handcrafted\", FILES_HAND[\"raw_status\"])\n",
    "movie_list_raw = pd.read_excel(ids_and_status)\n",
    "movie_list_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seen in seen_raw:\n",
    "    movieid = seen[0]\n",
    "    score = seen[1]\n",
    "    seen_raw_date = seen[2]\n",
    "    if movieid in movie_list_raw[\"tconst\"].values:\n",
    "        # if watched movie already in list\n",
    "        found_index = movie_list_raw.loc[movie_list_raw.loc[:,\"tconst\"]==movieid].index.tolist()[0]\n",
    "        movie_list_raw.at[found_index,\"enjoyment\"]\n",
    "        enjoyment = movie_list_raw.at[found_index,\"enjoyment\"]\n",
    "        watched = int(movie_list_raw.at[found_index,\"watched\"])\n",
    "        watched_date = movie_list_raw.at[found_index,\"watched_date\"]\n",
    "        if watched==1:\n",
    "            # update the score only if null\n",
    "            if(pd.isnull(enjoyment)):\n",
    "                movie_list_raw.at[found_index,\"enjoyment\"] = score\n",
    "            # update the date only if new data is not null\n",
    "            if(seen_raw_date != None):\n",
    "                movie_list_raw.at[found_index,\"watched_date\"] = seen_raw_date\n",
    "        elif watched==0:\n",
    "            # updated watched and add score (which can be nan)\n",
    "            movie_list_raw.at[found_index,\"enjoyment\"] = score\n",
    "            movie_list_raw.at[found_index,\"watched\"] = 1\n",
    "    else:\n",
    "        # if watched movie not in list\n",
    "        to_add = pd.Series({\n",
    "            'tconst':movieid, 'watched':1, 'netflix':np.nan,\n",
    "            'prime':np.nan, \"enjoyment\":score , \"priority\": np.nan})\n",
    "\n",
    "        movie_list_raw = pd.concat([movie_list_raw, to_add.to_frame().T], ignore_index=True)\n",
    "\n",
    "    # movie_list_raw.loc[movie_list_raw.loc[:,\"tconst\"]==movieid]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for movieid in unseen_raw:\n",
    "    if not movieid in movie_list_raw[\"tconst\"].values:\n",
    "        # if watched movie not already in list\n",
    "        to_add = pd.Series({\n",
    "            'tconst':movieid, 'watched':0, 'netflix':np.nan,\n",
    "            'prime':np.nan, \"enjoyment\":np.nan , \"priority\": np.nan})\n",
    "\n",
    "        movie_list_raw = pd.concat([movie_list_raw, to_add.to_frame().T], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_list_raw.sort_values([\"tconst\"]).to_excel(ids_and_status, index=False)\n",
    "del movie_list_raw"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean watched data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enjoyment score: 0=no; 1=mweh; 2=fun; 3=good; 4=great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watched = pd.read_excel(ids_and_status)\n",
    "watched[\"watched\"] = watched[\"watched\"].astype('Int64').astype(bool)\n",
    "watched[\"prime\"] = watched[\"prime\"].astype('Int64').replace(0, False).replace(1, True)\n",
    "watched[\"netflix\"] = watched[\"netflix\"].astype('Int64').replace(0, False).replace(1, True)\n",
    "watched[\"enjoyment\"] = watched[\"enjoyment\"].astype('float')\n",
    "watched[\"tconst\"] = watched[\"tconst\"].str.strip()\n",
    "watched"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add imdb data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add basic title data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_basics_file = os.path.join(\"data\", \"imdb\", FILES_IMDB[\"tit_bas\"])\n",
    "title_basics = pd.read_csv(title_basics_file, sep=\"\\t\")\n",
    "title_basics = title_basics.replace(to_replace = \"\\\\N\", value = np.nan)\n",
    "# title_watched = pd.merge(watched, title_basics, on=\"tconst\", how=\"left\") # new merge, keeps wrong stuff\n",
    "watched_title = pd.merge(watched, title_basics, on=\"tconst\", how=\"left\") # new merge, keeps wrong stuff\n",
    "del title_basics # cleanup memory by force\n",
    "watched_title"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_rate_file = os.path.join(\"data\", \"imdb\", FILES_IMDB[\"tit_rate\"])\n",
    "title_rate = pd.read_csv(title_rate_file, sep=\"\\t\")\n",
    "title_rate = title_rate.replace(to_replace = \"\\\\N\", value = np.nan)\n",
    "title_rate.loc[:,\"numVotes\"] = title_rate.loc[:,\"numVotes\"].astype('Int64')\n",
    "# watched_film_fin = pd.merge(watched_title,title_rate, on=\"tconst\", how=\"left\")\n",
    "watched_title_rate = pd.merge(watched_title,title_rate, on=\"tconst\", how=\"left\")\n",
    "del watched_title # cleanup memory by force\n",
    "watched_title_rate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add cast and crew"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### retrieve only needed cast and crew members from massive file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried all joining variations.\n",
    "Concat takes more than an hour.\n",
    "Merge takes less than 5 minutes.\n",
    "Join does not give the needed result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cast_crew_mega_file = os.path.join(\"data\", \"imdb\", FILES_IMDB[\"cast_crew\"])\n",
    "watched_films_cast  = pd.DataFrame(columns=[\"tconst\", \"ordering\",\"nconst\", \"category\", \"job\", \"characters\"])\n",
    "\n",
    "for chunk in pd.read_csv(cast_crew_mega_file, sep=\"\\t\", chunksize=1000):\n",
    "    rows = pd.merge(watched_title_rate.loc[:,\"tconst\"], chunk, on=\"tconst\", how=\"inner\")\n",
    "    watched_films_cast = pd.concat([rows,watched_films_cast], ignore_index = True)\n",
    "\n",
    "watched_films_cast.replace(to_replace = \"\\\\N\", value = np.nan, inplace=True)\n",
    "watched_films_cast.drop(['characters'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watched_films_cast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add cast and crew members to the movie list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watched_title_rate_personel = pd.merge(watched_title_rate, watched_films_cast, how='inner', on='tconst')\n",
    "del watched_title_rate\n",
    "del watched_films_cast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add info about personell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_file = os.path.join(\"data\", \"imdb\", FILES_IMDB[\"name_bas\"])\n",
    "names_basics = pd.read_csv(names_file, sep=\"\\t\")\n",
    "names_basics = names_basics.replace(to_replace = \"\\\\N\", value = np.nan)\n",
    "names_basics.loc[:,\"birthYear\"] = names_basics.loc[:,\"birthYear\"].astype('Int64')\n",
    "names_basics.loc[:,\"deathYear\"] = names_basics.loc[:,\"deathYear\"].astype('Int64')\n",
    "col_delete = [\"knownForTitles\"]\n",
    "names_basics = names_basics.drop(col_delete, axis=1)\n",
    "names_basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watched_title_rate_personel_names = pd.merge(watched_title_rate_personel, names_basics, how='left', on=\"nconst\")\n",
    "del watched_title_rate_personel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watched_title_rate_personel_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save the data as a pickle for step 2: processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = os.path.join(\"data\", \"generated\", FILES_GENERATED[\"films_raw\"])\n",
    "# watched_title_rate_personel_names\n",
    "watched_title_rate_personel_names.to_pickle(output)\n",
    "\n",
    "END_TIME = time.time()\n",
    "time_format = time.strftime(\"%H:%M:%S\", time.gmtime(END_TIME-START_TIME))\n",
    "print(\"Execution time: \",time_format)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c39b4c85bc2d9a02d0946a1a847d4c6ff09d2707df1e17d9736f60b3fc78dc0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
