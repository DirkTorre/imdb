# IMPORTANT NOTE:
tracking of improvements is now done in JIRA Software web app.


# current plan
- 1) convert to the new python and pandas:
    - (done) test the 'pipeline'
    - (done) clean compile_movie_list.py
    - clean the folder
    - upload to github
    - merge with master
- 2) improve the code:
    - 0) make sure that the newly added column in to_add works.
    - 1) use the data classes to remove redundancy of the path files in every script.
    - 2) code does not work with tags other than nm and tt, but an vi-id technically isn't a good thing to use, so maybe i should give the user a warning?
      just use the string as index, instead of converting it to an int.
      can always change it when i'm going to use a database.
    - 3) implement the pandas pipe function https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pipe.html
    - 4) create and/or remove OOP
    - 5) use logging to file with the dedicated logging method instead of a print to terminal
    - 6) clean scripts and add documentation / comments
- 3) further adjustments:
- use a database instead of parque files:
    https://pythontic.com/pandas/serialization/postgresql
    https://dlwhittenbury.github.io/imdb-3-building-the-imdb-mysql-database.html
    https://medium.com/@koustavin/imdb-sql-data-analysis-database-design-492751ab16c4
- start the 'dit is een gaaf score systeem' writen down in quick_stats.ipynb
- start ML in Python
- create GUI

# interesting thing:
    the principles file only contains the 10 most important figures of the movie.
    it does not contain the entire crew
    They probably did that because the crew data is way to big.


# general
- (done) update_movie_list.py heeft een bug: # to_add['link'] = to_add['link'].str.split("/",expand=True).loc[:,4].astype(str) # keyerror: 4
- werkt het ook met id's anders dan tt? >> vi2228618777
- tt-codes die (nog) niet in parquet files staan niet verwijderen uit lijst, ook een checkmark geven dat ze nog niet in huidige imdb database staan.
- (done) use two excell files to update the barebones movie list
- (done) update seen movies gives empty rows at top and bottom of file with watched status 1, very strange......
- (done) convert update_movie_list.ipynb to a python file (compile_movie_list.py)
- (done) redesign 'database'. Parqet works best with repeating values in columns. this also removes the need to do joins all the time. joins are expensive.
- (done) create a new branch
- (done) individual script for downloading data
- (done) convert saved data files to parquet.
- individual script that cleans the files (merge keys that are practically the same)
- if still needed, set feature types immediately.
- use parquet to only read specific columns and filter inmdiatly on rows (for score?).
      df = pd.read_parquet("myfile.parquet", filters=[('col_name', '<', 42)])
- use the pandas query function to filter.
- remove redundancy
- get rid of set1 = set1.group; set1 = set1.filter; etc.
- write good pandas
- use data classes instead of dictionaries for constant variables.
- convert 'generate_dataset.py' so it can be used with the ML pipeline.
- make a processing script according to the example that can be used with the ML pipeline.
    - keep track of normalization steps and vars
- train a basic model using the pipeline, change the previous scripts if needed
- execute model on all movies score > 5 to test the pipeline (to test if the batch convert works)

# keeping track
data is exploded on:
    - directors
    - writers
    - primaryProfession
    - knownForTitles

# Data preparation

cleaning data:
    - remove weird birth and death years
    - remove titles
    - remove columns:
        watched_date, netflix, prime, titleType, primaryTitle, originalTitle, isAdult, endYear
    - remove noise (outliers, stochastic, (rounding) errors)
    - remove attribute values:
        + genres: Music, Documentary, Wester, Sport, Musical, Short, Film-Noir.
        + averageRating: remove films with rating lower than 5. i wasn't going to watch those anyway.
        + category: remove production_manager, self, archive_footage
        + jobs: only keep 
    - nconst and tconst must be transformed to an integer
        + nconst: just remove the nm part and leading 0's. Then convert to integer.
        - tconst:just remove the tt part and leading 0's. Then convert to integer.
    - genres to binary columns
    - to int64: startYear, runtimeMinutes
    - what to do with NA's? (endYear, job, birthYear, deathYear?)
        + runtimeMinutes: fill them with whatever the mean version is of a Poisson distribution.
        + averageRating: remove items with scores lower than 5.

create new data:
    - create new info from the birth- and deathyear (age at release, stil living etc.)
    - create identifier from tconst, const and ...

transform data:
    - get rid of numvotes bias
    - get rid of birthyear, deathyear bias
    - round averageRating to nearest 0.5
    - runtimeMinutes follows poisson distribution.
    - birthyear: remove everything under 1900. drop na's. make 20 bins.
    - name_basics: primary_profession:  - If the values are independent form eachother, then we must transform them to 1 row/value.
                                        - If they are dependent on eachoter, then we must transform then as 1 column/value.
    - title_basics: genre:  - If the values are independent form eachother, then we must transform them to 1 row/value.
                            - If they are dependent on eachoter, then we must transform then as 1 column/value.

thinking:
    transform data:
        - substract 1900 from all years so the value is more representative?
        - round some years to nearest 5?
        - runtime minutes is practicly a Poisson distribution, make this standardized?
            + what to do with the flat ends? replace them with the start/end of the distribution? (wait that fucks up the distribution..)
            + fill missing values with Poisson version of the mean?
        - make averageRating more like a Poison distribution by randomly taking out data??
        - numVotes must be transformed. But both a high and low number of votes could give a bias. first remove very low numbers and outliers?
        - older movies with a higher score will get more and better reviews because of reccommendation. try to normalize this?
    cleaning data:
        - remove noise (outliers, stochastic, (rounding) errors)
            + genre: remove categories: Action, Adventure, Crime, Drama, Comedy?
            + category: remove categories: production_designer, self, archive_footage?
            + category: join actor and actress and make new column gender
            + some movies have way to many rows (200+) while others have a lot less (80-) would be better to take samples for every movie to even it out.
            + a lot of duplicates have ordering 5, maybe we can do something with this.
            + job: replace job categories that have less than 100 with empty. then replace them with category?
    effects on score:
        - does ordering have an effect?
        - a lot of duplicates have ordering number 5.
        - does gender (men, women, unknown) have an effect?
