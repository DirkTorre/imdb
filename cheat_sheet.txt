youtube:
    #rob_mulla

#pandas
- drop columns #pandas #removing
    df.drop(columns=['col1','col2'])

- string string in title style #pandas #string
    test["address"].str.title()

- split string on nth occurrence of char #pandas #string
    test["address"].str.split(" ", n=1)

- split string to new column #pandas #string
    test["address"].str.split(" ", expand=True)

- matrix to 2 column list to seperate variable-value pair #pandas #reformatting
    test.melt()

- matrix to 2 column list to seperate variable-value pair, plus add column and rename columns #pandas #reformatting
    test.melt(
    id_vars="species",
    value_vars=["Africa",'Asia'],
    var_name="continent",
    value_name="population")

- histogram plot with bins #pandas #plotting #bins
    dataframe.plot(kind='hist', bins=number)

- column of categories to multi one-hot columns: #pandas #one-hot #reformatting
    # make sure there are no lists by first using .explode('adress')
    test['adress'] = test['adress'].astype('category')
    pd.crosstab(test.index, test['adress'])

- get subset of dfa, using column values of dfz that are the same as as indices of dfa #subset
    dfa[dfa.index.isin(dfz['directors'])]
    
- collapse duplicate values of a column to a list, on basis of the index #reformatting #collapse
    directors['director'].groupby(level=0).apply(list)

-  values of a column (with duplicate id's) as columns #reformatting #collapse
    pd.pivot_table(personell, values='info', index=['tconst'], columns=['category'], aggfunc=list)





#general
- make list using list comprehension with an condition #listcomprehension
    [num for num in range(10) if num % 2]

- get index and value in for loop #loops
    for i, thing in enumerate(to_do):
        print(i, thing)

- making chained functions better to read #chain
    test = (
        thing
        .groupby(alksdjalksjd)
        .min()
        .fillna()
    )
- filter lists using filter() #lists #filter
    +++++

- get results from filter #lists #filter
    list(filter(thing))


#rest
- use logging module to check code #debugging
    works like print. can also send log to file or email etc.





#libraries
    Polars: a faster pandas (4x) uses lazy loading
    tqdm: progres bar for raw code and notebook
        - from tqdm import tqdm
        - from tqdm.notebook import tqdm
        for ting in tqdm(whatever):
    - spark: voor pipelines, kan script processen/data verdelen over meerdere nodes/computers
