{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "\n",
    "START_TIME = time.time()\n",
    "\n",
    "BASE_URL = \"https://datasets.imdbws.com/\"\n",
    "PARQ_PATH = \"data/imdb/parquet/\"\n",
    "DOWNLOAD_PATH = \"data/imdb/download/\"\n",
    "OUTPUT_PATH = \"data/generated/\"\n",
    "\n",
    "\n",
    "FILES_IMDB = {\n",
    "    \"cast_crew\" : \"title.crew.tsv\",\n",
    "    \"tit_bas\" : \"title.basics.tsv\",\n",
    "    \"tit_rate\" : \"title.ratings.tsv\",\n",
    "    \"name_bas\" : \"name.basics.tsv\",\n",
    "    \"tit_prin\" : \"title.principals.tsv\",\n",
    "}\n",
    "\n",
    "FILES_IMDB_PARQ = {\n",
    "    \"tit_bas\" : \"title_basics.parquet\",\n",
    "    \"genres\" : \"genres.parquet\",\n",
    "    \"tit_rate\" : \"title_ratings.parquet\",\n",
    "    'directors' : 'directors.parquet',\n",
    "    'writers' : 'writers.parquet',\n",
    "    'prim_prof' : 'primary_profession.parquet',\n",
    "    'known_for' : 'known_for_titles.parquet',\n",
    "    'name_bas' : 'name_basics.parquet',\n",
    "    'const' : 'ids.parquet',\n",
    "    'ordering' : 'ordering.parquet',\n",
    "    'character' : 'character.parquet',\n",
    "    'job' : 'job.parquet',\n",
    "}\n",
    "\n",
    "FILES_HAND = {\n",
    "    \"raw_status\": \"raw_status.xlsx\",\n",
    "    \"to_add\" : \"to_add.xlsx\"\n",
    "}\n",
    "\n",
    "FILES_GENERATED = {\n",
    "    \"films_raw\": \"films_raw.pkl\",\n",
    "    \"films_reading\": \"films_reading.xlsx\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setAttr(frame):\n",
    "    # setting column types\n",
    "    frame['watched_date'] = pd.to_datetime(frame['watched_date'])\n",
    "    frame[['enjoyment','story','subject','acting','visual','action','comedy']] = frame[['enjoyment','story','subject','acting','visual','action','comedy']].astype(float)\n",
    "    frame['watched'] = frame['watched'].astype(\"Int64\").replace(0,np.nan)\n",
    "    frame[['netflix','prime','priority']] = frame[['netflix','prime','priority']].astype(\"Int64\")\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    \"\"\"Loads the raw excel files.\"\"\"\n",
    "    # load data and set types of films to add\n",
    "    id_stat = os.path.join(\"data\", \"handcrafted\", FILES_HAND[\"to_add\"])\n",
    "    to_add = setAttr(pd.read_excel(id_stat))\n",
    "    # convert link to tconstant\n",
    "    to_add['link'] = to_add['link'].str.split(\"/\",expand=True).loc[:,4].astype(str)\n",
    "    # remove duplicates\n",
    "    to_add = to_add.drop_duplicates().rename(columns={\"link\":\"tconst\"})\n",
    "    # add index as column\n",
    "    to_add[\"row_index\"] = to_add.index\n",
    "    to_add = to_add.set_index(\"tconst\")\n",
    "    # set nan to 0\n",
    "    to_add.loc[:,['priority', 'watched']] = to_add.loc[:,['priority', 'watched']].fillna(0)\n",
    "\n",
    "    # loading and preparing film list\n",
    "    raw_stat_link = os.path.join(\"data\", \"handcrafted\", FILES_HAND[\"raw_status\"])\n",
    "    raw_stat = setAttr(pd.read_excel(raw_stat_link))\n",
    "    raw_stat = raw_stat.drop_duplicates().set_index(\"tconst\")\n",
    "    # set nan to 0\n",
    "    raw_stat.loc[:,['priority', 'watched']] = raw_stat.loc[:,['priority', 'watched']].fillna(0)\n",
    "\n",
    "    return to_add, raw_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeDuplicates(to_add):\n",
    "    # the new and improved function 26 jan 2024\n",
    "    # fixing watched, priority, netflix, prime\n",
    "    # replace value with highest value (if a movie has a 1, all duplicates get to be 1)\n",
    "\n",
    "    # Because new data is appended at the end (CHECK THIS),\n",
    "    # we can identify new data by a bigger row number.\n",
    "    if \"row_index\" not in to_add.columns:\n",
    "        to_add[\"row_index\"] = range(to_add.shape[0])\n",
    "\n",
    "    for col_name in [\"watched\", \"priority\", \"netflix\", \"prime\"]:\n",
    "        new = (to_add\n",
    "            .sort_values([\"tconst\", col_name],ascending=False)\n",
    "            .reset_index()\n",
    "            .drop_duplicates(subset=[\"tconst\"],keep=\"first\")\n",
    "            .loc[:,[\"tconst\", col_name]])\n",
    "        to_add.update(new.set_index(\"tconst\"), overwrite=True)\n",
    "\n",
    "    # fixing scores\n",
    "    # keep the latest score, unless the is no score than move to the next\n",
    "    for score_cat in [\"enjoyment\", \"story\", \"subject\", \"acting\", \"visual\", \"action\", \"comedy\"]:\n",
    "        new_score = (to_add.sort_values([\"tconst\",\"watched_date\",\"row_index\"],ascending=False)\n",
    "                     .reset_index()\n",
    "                     .loc[:,[\"tconst\", score_cat]]\n",
    "                     .dropna()\n",
    "                     .drop_duplicates(subset=[\"tconst\"],keep=\"first\"))\n",
    "        to_add.update(new_score.set_index(\"tconst\"), overwrite=True)\n",
    "\n",
    "    # effective way of assigning the latest date to a movie.\n",
    "    # keep in mind that this must be done at the end, otherwise is screws over the ordering.\n",
    "    new_watched_date_values = (to_add\n",
    "                               .reset_index()\n",
    "                               .sort_values([\"tconst\",\"watched_date\"],ascending=False)\n",
    "                               .drop_duplicates(subset=[\"tconst\"],keep=\"first\")[[\"tconst\",\"watched_date\"]]\n",
    "                               .set_index(\"tconst\"))\n",
    "    to_add.update(new_watched_date_values)\n",
    "\n",
    "    # drop row_index column\n",
    "    to_add = to_add.drop(columns=\"row_index\")\n",
    "\n",
    "    # remove rows that have no data\n",
    "    to_add = to_add[to_add.index!=\"nan\"]\n",
    "\n",
    "    # removing duplicates\n",
    "    return to_add.reset_index().drop_duplicates(ignore_index=False).set_index(\"tconst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# first make a backup of the data before testing this out\n",
    "code is commented out for safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_add, raw_stat = loadData()\n",
    "\n",
    "# to_add = removeDuplicates(to_add)\n",
    "\n",
    "# # Merge the old data with the new data.\n",
    "# # Keep in mind that duplicates that were in in raw_stat from the start are also removed.\n",
    "# # It's important to add the newest data at the end.\n",
    "# # This is because we are going to number the rows.\n",
    "# # Older data get's a higher number.\n",
    "# raw_stat = removeDuplicates(pd.concat([raw_stat, to_add]))\n",
    "\n",
    "# # overwrite raw_status\n",
    "# output = os.path.join(\"data\", \"handcrafted\", FILES_HAND[\"raw_status\"])\n",
    "# raw_stat.sort_index().to_excel(output)\n",
    "\n",
    "# # empty to_add.xlsx\n",
    "# new_empty = pd.DataFrame(data=None, columns=[\"link\"]+to_add.columns.to_list())\n",
    "# to_add = os.path.join(\"data\", \"handcrafted\", FILES_HAND[\"to_add\"])\n",
    "# new_empty.to_excel(to_add, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
